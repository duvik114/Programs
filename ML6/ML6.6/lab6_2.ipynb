{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import chi2, SelectKBest, SequentialFeatureSelector, SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from skfeature.function.similarity_based import fisher_score\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv('data/SMS.tsv',sep='\\t')\n",
    "ds.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['class'] = pd.factorize(ds['class'])[0] # ham - 0, spam - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ds['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = []\n",
    "for s in ds['text']:\n",
    "    s = s.translate(str.maketrans('', '', string.punctuation))\n",
    "    s = re.sub('\\s+', ' ', s)\n",
    "    s = re.sub('\\d+', '', s)\n",
    "    X_text.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114    0\n",
       "3589    0\n",
       "3095    0\n",
       "1012    0\n",
       "3320    0\n",
       "       ..\n",
       "4931    1\n",
       "3264    0\n",
       "1653    1\n",
       "2607    0\n",
       "2732    0\n",
       "Name: class, Length: 4457, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=400, stop_words=stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(X_text)\n",
    "X = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Встроенный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call      7.717350e-02\n",
      "txt       5.760009e-02\n",
      "free      4.776983e-02\n",
      "claim     4.060314e-02\n",
      "mobile    3.559542e-02\n",
      "              ...     \n",
      "hair      1.604888e-06\n",
      "shes      1.433198e-06\n",
      "dude      6.066155e-07\n",
      "face      5.481904e-07\n",
      "called    4.026351e-08\n",
      "Length: 400, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "coef=pd.Series(rf.feature_importances_, X.columns).sort_values(ascending=False)\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_emb = pd.Series(rf.feature_importances_, X.columns).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "обёртка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  30 , added  call\n",
      "Step  30 , added  free\n",
      "Step  30 , added  stop\n",
      "Step  30 , added  text\n",
      "Step  30 , added  reply\n",
      "Step  30 , added  mobile\n",
      "Step  30 , added  claim\n",
      "Step  30 , added  txt\n",
      "Step  30 , added  ur\n",
      "Step  30 , added  service\n",
      "Step  30 , added  win\n",
      "Step  30 , added  prize\n",
      "Step  30 , added  contact\n",
      "Step  30 , added  per\n",
      "Step  30 , added  ltgt\n",
      "Step  30 , added  urgent\n",
      "Step  30 , added  customer\n",
      "Step  30 , added  cash\n",
      "Step  30 , added  guaranteed\n",
      "Step  30 , added  code\n",
      "Step  30 , added  shows\n",
      "Step  30 , added  latest\n",
      "Step  30 , added  nokia\n",
      "Step  30 , added  tone\n",
      "Step  30 , added  new\n",
      "Step  30 , added  ringtone\n",
      "Step  30 , added  mins\n",
      "Step  30 , added  awarded\n",
      "Step  30 , added  pobox\n",
      "Step  30 , added  mob\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "n = 400\n",
    "# X_train\n",
    "\n",
    "coef_wrap = []\n",
    "features_rest = X_train\n",
    "num_of_features = 30\n",
    "while len(coef_wrap) < num_of_features:\n",
    "    lr.fit(features_rest, y_train)\n",
    "    model_fi = permutation_importance(lr, features_rest, y_train)\n",
    "    max_value = max(model_fi['importances_mean'])\n",
    "    max_index = np.argmax(model_fi['importances_mean'])\n",
    "    print('Step ', (len(coef_wrap) + 1), ', added ', features_rest.columns[max_index])\n",
    "    coef_wrap.append(features_rest.columns[max_index])\n",
    "    features_rest = features_rest.drop(features_rest.columns[max_index], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_filt = X_train\n",
    "\n",
    "# while len(X_train_filt.columns) > 100:\n",
    "#     tree = DecisionTreeClassifier()\n",
    "#     tree.fit(X_train_filt, y_train)\n",
    "#     coef=pd.Series(tree.feature_importances_, X_train_filt.columns).sort_values()\n",
    "#     for i in range(10):\n",
    "#         X_train_filt = X_train_filt.drop(coef.index[i], axis=1)  \n",
    "\n",
    "# coef_wrap = coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gud       4.028746e-07\n",
       "also      4.360379e-07\n",
       "said      4.754627e-07\n",
       "hey       5.177381e-07\n",
       "lol       5.274363e-07\n",
       "              ...     \n",
       "mobile    3.402037e-02\n",
       "win       3.614163e-02\n",
       "stop      4.696544e-02\n",
       "txt       1.533898e-01\n",
       "call      2.510207e-01\n",
       "Length: 110, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coef_wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "фильтр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filter = X_train\n",
    "\n",
    "corr = X_train_filter.corr(method='pearson')\n",
    "\n",
    "corr_class = corr['class']\n",
    "coef_filt = corr_class.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ur       -0.017787\n",
       "free     -0.015515\n",
       "call     -0.014843\n",
       "send     -0.013854\n",
       "text     -0.013242\n",
       "            ...   \n",
       "yo        0.038234\n",
       "todays    0.045150\n",
       "go        0.046247\n",
       "coming    0.057272\n",
       "class     1.000000\n",
       "Name: class, Length: 400, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Встроенный метод: \n",
      "['call' 'txt' 'free' 'claim' 'mobile' 'stop' 'prize' 'text' 'win' 'reply'\n",
      " 'service' 'cash' 'urgent' 'nokia' 'contact' 'chat' 'tone' 'ur' 'box'\n",
      " 'per' 'customer' 'tones' 'send' 'new' 'ppm' 'ringtone' 'guaranteed' 'sms'\n",
      " 'apply' 'landline']\n",
      "\n",
      "Метод обертка: \n",
      "['call' 'txt' 'stop' 'win' 'mobile' 'send' 'text' 'free' 'tones' 'reply'\n",
      " 'claim' 'ur' 'im' 'got' 'get' 'tell' 'sexy' 'pmin' 'later' 'important'\n",
      " 'contact' 'new' 'per' 'cost' 'time' 'give' 'calls' 'ringtone' 'box' 'ask']\n",
      "\n",
      "Фильтрующий метод: \n",
      "['coming' 'go' 'todays' 'yo' 'done' 'able' 'saw' 'st' 'says' 'theres'\n",
      " 'got' 'run' 'though' 'yeah' 'day' 'join' 'early' 'might' 'whats'\n",
      " 'tomorrow' 'minutes' 'gonna' 'hi' 'sure' 'name' 'wanna' 'holiday' 'sorry'\n",
      " 'us']\n"
     ]
    }
   ],
   "source": [
    "print('Встроенный метод: ')\n",
    "print(np.array(coef_emb.index[-30:])[::-1])\n",
    "print()\n",
    "print('Метод обертка: ')\n",
    "print(np.array(coef_wrap.index[-30:])[::-1])\n",
    "print()\n",
    "print('Фильтрующий метод: ')\n",
    "print(np.array(coef_filt.index[-30:-1])[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fish = X_train\n",
    "ranks = fisher_score.fisher_score(X_train_fish.to_numpy(), y_train.to_numpy())\n",
    "feature_importances = pd.Series(ranks, X_train_fish.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['juz', 'princess', 'say', 'nice', 'way', 'xmas', 'world', 'whats',\n",
       "       'get', 'im', 'everything', 'cool', 'shes', 'tmr', 'talk', 'night', 'hi',\n",
       "       'customer', 'stop', 'cos', 'plus', 'take', 'anyway', 'tomorrow', 'real',\n",
       "       'something', 'know', 'remember', 'friend', 'bed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(feature_importances.sort_values(ascending=True)[:40])\n",
    "res_fish = feature_importances.sort_values(ascending=True)[:30].index\n",
    "res_fish\n",
    "# print(feature_importances[:40])\n",
    "# print(X_train_fish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rec = X_train\n",
    "lr = LogisticRegression(class_weight = 'balanced', solver = 'lbfgs', random_state=42, n_jobs=-1, max_iter=50)\n",
    "rfe = RFE(lr, n_features_to_select=30)\n",
    "rfe = rfe.fit(X_train_rec, y_train)\n",
    "# y_pred = X_train_rec.iloc[ : ,rfe.get_support()]\n",
    "# y_pred = rfe.predict(X_train_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['box', 'call', 'cash', 'chat', 'claim', 'code', 'collect', 'contact',\n",
      "       'cost', 'free', 'gift', 'ill', 'important', 'landline', 'mob', 'mobile',\n",
      "       'pmin', 'prize', 'reply', 'ringtone', 'send', 'service', 'sexy', 'stop',\n",
      "       'text', 'tone', 'tones', 'txt', 'urgent', 'win'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "res_rec = X_train_rec.iloc[ : ,rfe.get_support()]\n",
    "print(res_rec.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хи-квадрат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['awarded', 'box', 'call', 'cash', 'claim', 'code', 'contact',\n",
      "       'customer', 'free', 'guaranteed', 'landline', 'latest', 'mobile',\n",
      "       'nokia', 'per', 'po', 'pobox', 'ppm', 'prize', 'reply', 'ringtone',\n",
      "       'service', 'shows', 'stop', 'text', 'tone', 'tones', 'txt', 'urgent',\n",
      "       'win'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# X_train_chi2 = X_train\n",
    "# select_chi2 = SelectKBest(chi2, k = 30)\n",
    "# select_chi2.fit_transform(X_train_chi2, y_train)\n",
    "# X_chi2 = X_train_chi2.iloc[ : ,select_chi2.get_support()]\n",
    "\n",
    "# print(X_chi2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['call', 'cant', 'chat', 'claim', 'contact', 'dis', 'everything', 'free',\n",
      "       'good', 'help', 'mobile', 'oso', 'per', 'play', 'pmin', 'ppm', 'quite',\n",
      "       'reply', 'ringtone', 'service', 'shows', 'sure', 'tell', 'tmr', 'told',\n",
      "       'tones', 'txt', 'urgent', 'win', 'xmas'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# X_train_sfs = X_train\n",
    "# tree = DecisionTreeClassifier()\n",
    "# sfs = SequentialFeatureSelector(tree, n_features_to_select=30)\n",
    "# sfs.fit(X_train_sfs, y_train)\n",
    "# X_sfs = X_train_sfs.iloc[ : ,sfs.get_support()]\n",
    "\n",
    "# print(X_sfs.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Встроенный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "Index(['account', 'apply', 'box', 'call', 'cash', 'chat', 'claim', 'code',\n",
      "       'collect', 'contact', 'cost', 'customer', 'find', 'free', 'help', 'ill',\n",
      "       'im', 'landline', 'later', 'ltgt', 'message', 'mins', 'mobile', 'new',\n",
      "       'nokia', 'ok', 'per', 'please', 'ppm', 'prize', 'receive', 'reply',\n",
      "       'ringtone', 'send', 'service', 'shows', 'stop', 'text', 'tone', 'tones',\n",
      "       'txt', 'ur', 'urgent', 'win'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_train_emb = X_train\n",
    "selector = SelectFromModel(\n",
    "    LogisticRegression(C=0.25, penalty='l1',solver='liblinear', random_state=10))\n",
    "\n",
    "selector.fit(X_train_emb, y_train)\n",
    "X_emb = X_train_emb.iloc[ : ,selector.get_support()]\n",
    "\n",
    "print(len(X_emb.columns))\n",
    "print(X_emb.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мои реализации: \n",
      "['apply', 'box', 'call', 'cash', 'chat', 'claim', 'contact', 'customer', 'free', 'guaranteed', 'landline', 'mobile', 'new', 'nokia', 'per', 'ppm', 'prize', 'reply', 'ringtone', 'send', 'service', 'sms', 'stop', 'text', 'tone', 'tones', 'txt', 'ur', 'urgent', 'win']\n",
      "['awarded', 'call', 'cash', 'claim', 'code', 'contact', 'customer', 'free', 'guaranteed', 'latest', 'ltgt', 'mins', 'mob', 'mobile', 'new', 'nokia', 'per', 'pobox', 'prize', 'reply', 'ringtone', 'service', 'shows', 'stop', 'text', 'tone', 'txt', 'ur', 'urgent', 'win']\n",
      "['able', 'coming', 'day', 'done', 'early', 'go', 'gonna', 'got', 'hi', 'holiday', 'join', 'might', 'minutes', 'name', 'run', 'saw', 'says', 'sorry', 'st', 'sure', 'theres', 'though', 'todays', 'tomorrow', 'us', 'wanna', 'whats', 'yeah', 'yo']\n",
      "\n",
      "Библиотечные: \n",
      "['anyway', 'bed', 'cool', 'cos', 'customer', 'everything', 'friend', 'get', 'hi', 'im', 'juz', 'know', 'nice', 'night', 'plus', 'princess', 'real', 'remember', 'say', 'shes', 'something', 'stop', 'take', 'talk', 'tmr', 'tomorrow', 'way', 'whats', 'world', 'xmas']\n",
      "['box', 'call', 'cash', 'chat', 'claim', 'code', 'collect', 'contact', 'cost', 'free', 'gift', 'ill', 'important', 'landline', 'mob', 'mobile', 'pmin', 'prize', 'reply', 'ringtone', 'send', 'service', 'sexy', 'stop', 'text', 'tone', 'tones', 'txt', 'urgent', 'win']\n",
      "['account', 'apply', 'box', 'call', 'cash', 'chat', 'claim', 'code', 'collect', 'contact', 'cost', 'customer', 'find', 'free', 'help', 'ill', 'im', 'landline', 'later', 'ltgt', 'message', 'mins', 'mobile', 'new', 'nokia', 'ok', 'per', 'please', 'ppm', 'prize', 'receive', 'reply', 'ringtone', 'send', 'service', 'shows', 'stop', 'text', 'tone', 'tones', 'txt', 'ur', 'urgent', 'win']\n"
     ]
    }
   ],
   "source": [
    "print('Мои реализации: ')\n",
    "print(sorted(np.array(coef_emb.index[-30:])))\n",
    "print(sorted(np.array(coef_wrap)))\n",
    "print(sorted(np.array(coef_filt.index[-30:-1])[::-1]))\n",
    "print()\n",
    "print('Библиотечные: ')\n",
    "print(sorted(np.array(res_fish)))\n",
    "print(sorted(np.array(res_rec.columns)))\n",
    "print(sorted(np.array(X_emb.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    KNeighborsClassifier(n_neighbors=100),\n",
    "    RandomForestClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_in_emb = pd.DataFrame(X_train, columns = np.array(coef_emb.index[-30:]))\n",
    "X_train_wrap = pd.DataFrame(X_train, columns = np.array(coef_wrap))\n",
    "X_train_filt = pd.DataFrame(X_train, columns = np.array(coef_filt.index[-30:-1])[::-1])\n",
    "X_train_fish = pd.DataFrame(X_train, columns = np.array(res_fish))\n",
    "X_train_rec = pd.DataFrame(X_train, columns = np.array(res_rec.columns))\n",
    "X_train_X_emb = pd.DataFrame(X_train, columns = np.array(X_emb.columns))\n",
    "\n",
    "X_test_in_emb = pd.DataFrame(X_test, columns = np.array(coef_emb.index[-30:]))\n",
    "X_test_wrap = pd.DataFrame(X_test, columns = np.array(coef_wrap))\n",
    "X_test_filt = pd.DataFrame(X_test, columns = np.array(coef_filt.index[-30:-1])[::-1])\n",
    "X_test_fish = pd.DataFrame(X_test, columns = np.array(res_fish))\n",
    "X_test_rec = pd.DataFrame(X_test, columns = np.array(res_rec.columns))\n",
    "X_test_X_emb = pd.DataFrame(X_test, columns = np.array(X_emb.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_in_emb\n",
    "# X_train_wrap\n",
    "# X_train_filt\n",
    "# X_train_fish\n",
    "# X_train_rec\n",
    "# X_train_X_emb\n",
    "\n",
    "def print_res(classifier):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test) \n",
    "    print('До выбора признаков: ', accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    classifier.fit(X_train_in_emb, y_train)\n",
    "    y_pred = classifier.predict(X_test_in_emb) \n",
    "    print('После выбора признаков: ', accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    classifier.fit(X_train_wrap, y_train)\n",
    "    y_pred = classifier.predict(X_test_wrap) \n",
    "    print('После выбора признаков: ', accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    classifier.fit(X_train_filt, y_train)\n",
    "    y_pred = classifier.predict(X_test_filt) \n",
    "    print('После выбора признаков: ', accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    classifier.fit(X_train_fish, y_train)\n",
    "    y_pred = classifier.predict(X_test_fish) \n",
    "    print('После выбора признаков: ', accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    classifier.fit(X_train_rec, y_train)\n",
    "    y_pred = classifier.predict(X_test_rec) \n",
    "    print('После выбора признаков: ', accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    classifier.fit(X_train_X_emb, y_train)\n",
    "    y_pred = classifier.predict(X_test_X_emb) \n",
    "    print('После выбора признаков: ', accuracy_score(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "До выбора признаков:  0.9766816143497757\n",
      "После выбора признаков:  0.9443946188340807\n",
      "После выбора признаков:  0.9461883408071748\n",
      "После выбора признаков:  0.8565022421524664\n",
      "После выбора признаков:  0.862780269058296\n",
      "После выбора признаков:  0.9399103139013453\n",
      "После выбора признаков:  0.9542600896860987\n",
      "До выбора признаков:  0.8565022421524664\n",
      "После выбора признаков:  0.8771300448430494\n",
      "После выбора признаков:  0.8807174887892377\n",
      "После выбора признаков:  0.8565022421524664\n",
      "После выбора признаков:  0.8672645739910314\n",
      "После выбора признаков:  0.8896860986547085\n",
      "После выбора признаков:  0.8663677130044843\n",
      "До выбора признаков:  0.9775784753363229\n",
      "После выбора признаков:  0.9614349775784753\n",
      "После выбора признаков:  0.9614349775784753\n",
      "После выбора признаков:  0.873542600896861\n",
      "После выбора признаков:  0.8834080717488789\n",
      "После выбора признаков:  0.9659192825112107\n",
      "После выбора признаков:  0.968609865470852\n"
     ]
    }
   ],
   "source": [
    "for cl in classifiers:\n",
    "    print_res(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
